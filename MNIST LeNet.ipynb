{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, Adagrad, Adadelta, RMSprop\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class LeNet(Module):\n",
    "    def __init__(self, act=nn.ReLU(), pool=nn.MaxPool2d(2)):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = act\n",
    "        self.pool1 = pool\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = act\n",
    "        self.pool2 = pool\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.relu3 = act\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = act\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu5 = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return y\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size= 256, epochs=100, lr=0.01, act=nn.ReLU(), pool=nn.MaxPool2d(2), optim=\"adam\"):\n",
    "    startTime = time.time()\n",
    "    batch_size = batch_size\n",
    "    train_dataset = mnist.MNIST(root='./data_MNIST/train', train=True, transform=ToTensor())\n",
    "    test_dataset = mnist.MNIST(root='./data_MNIST/test', train=False, transform=ToTensor())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = LeNet(act=act, pool=pool)\n",
    "    \n",
    "    if optim == \"adam\":\n",
    "        optimizer = Adam(model.parameters(), lr=lr)\n",
    "    elif optim == \"adagrad\":\n",
    "        optimizer = Adagrad(model.parameters(), lr=lr)\n",
    "    elif optim == \"sgdWithMomentum\":\n",
    "        optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    else: \n",
    "        optimizer = SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    cost = CrossEntropyLoss()\n",
    "    epoch = epochs\n",
    "    for _epoch in range(epoch):\n",
    "        model.train()\n",
    "        loss = 0\n",
    "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "            label_np = np.zeros((train_label.shape[0], 10))\n",
    "            optimizer.zero_grad()\n",
    "            predict_y = model(train_x.float())\n",
    "            loss = cost(predict_y, train_label.long())\n",
    "            if idx % 10 == 0:\n",
    "                # print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
    "                pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        correct = 0\n",
    "        _sum = 0\n",
    "        model.eval()\n",
    "        for idx, (test_x, test_label) in enumerate(test_loader):\n",
    "            predict_y = model(test_x.float()).detach()\n",
    "            predict_ys = np.argmax(predict_y, axis=-1)\n",
    "            label_np = test_label.numpy()\n",
    "            _ = predict_ys == test_label\n",
    "            correct += np.sum(_.numpy(), axis=-1)\n",
    "            _sum += _.shape[0]\n",
    "        if _epoch % 5 == 0:\n",
    "            print('Epoch {:.2f},  loss: {:.2f},  accuracy: {:.2f}'.format(_epoch, loss, correct / _sum), )\n",
    "    print(\"Took: \" + str((time.time() - startTime).__round__(2)) +\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.00,  loss: 2.28,  accuracy: 0.12\n",
      "Epoch 5.00,  loss: 1.43,  accuracy: 0.78\n",
      "Epoch 10.00,  loss: 1.18,  accuracy: 0.81\n",
      "Epoch 15.00,  loss: 1.10,  accuracy: 0.83\n",
      "Epoch 20.00,  loss: 1.05,  accuracy: 0.85\n",
      "Epoch 25.00,  loss: 1.01,  accuracy: 0.88\n",
      "Epoch 30.00,  loss: 0.98,  accuracy: 0.91\n",
      "Epoch 35.00,  loss: 0.95,  accuracy: 0.92\n",
      "Epoch 40.00,  loss: 0.93,  accuracy: 0.93\n",
      "Epoch 45.00,  loss: 0.91,  accuracy: 0.94\n",
      "Epoch 50.00,  loss: 0.90,  accuracy: 0.94\n",
      "Epoch 55.00,  loss: 0.89,  accuracy: 0.94\n",
      "Epoch 60.00,  loss: 0.88,  accuracy: 0.95\n",
      "Epoch 65.00,  loss: 0.87,  accuracy: 0.95\n",
      "Epoch 70.00,  loss: 0.87,  accuracy: 0.95\n",
      "Epoch 75.00,  loss: 0.86,  accuracy: 0.96\n",
      "Epoch 80.00,  loss: 0.86,  accuracy: 0.96\n",
      "Epoch 85.00,  loss: 0.86,  accuracy: 0.96\n",
      "Epoch 90.00,  loss: 0.85,  accuracy: 0.96\n",
      "Epoch 95.00,  loss: 0.85,  accuracy: 0.97\n",
      "Took: 783.81 seconds\n"
     ]
    }
   ],
   "source": [
    "# Normal\n",
    "train(batch_size= 256, epochs=100, lr=0.01, act=nn.Tanh(), pool=nn.AvgPool2d(2), optim=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comment\n",
    " Best one. Worked very well\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.00,  loss: 2.30,  accuracy: 0.10\n",
      "Epoch 5.00,  loss: 2.20,  accuracy: 0.34\n",
      "Epoch 10.00,  loss: 1.05,  accuracy: 0.63\n",
      "Epoch 15.00,  loss: 0.66,  accuracy: 0.73\n",
      "Epoch 20.00,  loss: 0.60,  accuracy: 0.76\n",
      "Epoch 25.00,  loss: 0.57,  accuracy: 0.77\n",
      "Epoch 30.00,  loss: 0.55,  accuracy: 0.78\n",
      "Epoch 35.00,  loss: 0.54,  accuracy: 0.78\n",
      "Epoch 40.00,  loss: 0.53,  accuracy: 0.78\n",
      "Epoch 45.00,  loss: 0.53,  accuracy: 0.78\n",
      "Epoch 50.00,  loss: 0.53,  accuracy: 0.78\n",
      "Epoch 55.00,  loss: 0.53,  accuracy: 0.79\n",
      "Epoch 60.00,  loss: 0.53,  accuracy: 0.79\n",
      "Epoch 65.00,  loss: 0.53,  accuracy: 0.79\n",
      "Epoch 70.00,  loss: 0.53,  accuracy: 0.79\n",
      "Epoch 75.00,  loss: 0.53,  accuracy: 0.79\n",
      "Epoch 80.00,  loss: 0.52,  accuracy: 0.79\n",
      "Epoch 85.00,  loss: 0.52,  accuracy: 0.79\n",
      "Epoch 90.00,  loss: 0.52,  accuracy: 0.79\n",
      "Epoch 95.00,  loss: 0.52,  accuracy: 0.79\n",
      "Took: 782.01 seconds\n"
     ]
    }
   ],
   "source": [
    "# Q1 ReLU instead of Tanh.  MaxPool instead of AvgPool. \n",
    "train(batch_size= 256, epochs=100, lr=0.01, act=nn.ReLU(), pool=nn.MaxPool2d(2), optim=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comment\n",
    "Not much improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.00,  loss: 2.30,  accuracy: 0.14\n",
      "Epoch 5.00,  loss: 1.02,  accuracy: 0.66\n",
      "Epoch 10.00,  loss: 0.99,  accuracy: 0.68\n",
      "Epoch 15.00,  loss: 0.98,  accuracy: 0.69\n",
      "Epoch 20.00,  loss: 0.69,  accuracy: 0.78\n",
      "Epoch 25.00,  loss: 0.64,  accuracy: 0.79\n",
      "Epoch 30.00,  loss: 0.63,  accuracy: 0.79\n",
      "Epoch 35.00,  loss: 0.62,  accuracy: 0.79\n",
      "Epoch 40.00,  loss: 0.61,  accuracy: 0.80\n",
      "Epoch 45.00,  loss: 0.61,  accuracy: 0.80\n",
      "Epoch 50.00,  loss: 0.60,  accuracy: 0.80\n",
      "Epoch 55.00,  loss: 0.60,  accuracy: 0.80\n",
      "Epoch 60.00,  loss: 0.60,  accuracy: 0.80\n",
      "Epoch 65.00,  loss: 0.59,  accuracy: 0.80\n",
      "Epoch 70.00,  loss: 0.59,  accuracy: 0.80\n",
      "Epoch 75.00,  loss: 0.59,  accuracy: 0.80\n",
      "Epoch 80.00,  loss: 0.58,  accuracy: 0.80\n",
      "Epoch 85.00,  loss: 0.58,  accuracy: 0.80\n",
      "Epoch 90.00,  loss: 0.57,  accuracy: 0.80\n",
      "Epoch 95.00,  loss: 0.57,  accuracy: 0.80\n",
      "Took: 945.34 seconds\n"
     ]
    }
   ],
   "source": [
    "# Q2 Try different batch sizes\n",
    "train(batch_size= 128, epochs=100, lr=0.01, act=nn.ReLU(), pool=nn.MaxPool2d(2), optim=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comment \n",
    " Accuracy increased a little but loss was not much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.00,  loss: 2.30,  accuracy: 0.10\n",
      "Epoch 5.00,  loss: 2.30,  accuracy: 0.10\n",
      "Epoch 10.00,  loss: 2.30,  accuracy: 0.10\n",
      "Epoch 15.00,  loss: 2.30,  accuracy: 0.14\n",
      "Epoch 20.00,  loss: 2.30,  accuracy: 0.19\n",
      "Epoch 25.00,  loss: 2.29,  accuracy: 0.20\n",
      "Epoch 30.00,  loss: 2.29,  accuracy: 0.26\n",
      "Epoch 35.00,  loss: 2.28,  accuracy: 0.35\n",
      "Epoch 40.00,  loss: 2.27,  accuracy: 0.41\n",
      "Epoch 45.00,  loss: 2.24,  accuracy: 0.43\n",
      "Epoch 50.00,  loss: 2.14,  accuracy: 0.44\n",
      "Epoch 55.00,  loss: 1.79,  accuracy: 0.49\n",
      "Epoch 60.00,  loss: 1.43,  accuracy: 0.54\n",
      "Epoch 65.00,  loss: 1.27,  accuracy: 0.58\n",
      "Epoch 70.00,  loss: 1.18,  accuracy: 0.62\n",
      "Epoch 75.00,  loss: 1.12,  accuracy: 0.65\n",
      "Epoch 80.00,  loss: 1.08,  accuracy: 0.66\n",
      "Epoch 85.00,  loss: 1.05,  accuracy: 0.67\n",
      "Epoch 90.00,  loss: 1.02,  accuracy: 0.69\n",
      "Epoch 95.00,  loss: 1.00,  accuracy: 0.70\n",
      "Took: 929.09 seconds\n"
     ]
    }
   ],
   "source": [
    "# Q3.1 Normal with lr low \n",
    "train(batch_size= 256, epochs=100, lr=0.001, act=nn.ReLU(), pool=nn.MaxPool2d(2), optim=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comment\n",
    " Due to low learning rate, accuracy was not improved a lot on 100 epoch. Underfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.00,  loss: 1.23,  accuracy: 0.72\n",
      "Epoch 5.00,  loss: 0.17,  accuracy: 0.97\n",
      "Epoch 10.00,  loss: 0.16,  accuracy: 0.98\n",
      "Epoch 15.00,  loss: 0.16,  accuracy: 0.98\n",
      "Epoch 20.00,  loss: 0.15,  accuracy: 0.98\n",
      "Epoch 25.00,  loss: 0.13,  accuracy: 0.98\n",
      "Epoch 30.00,  loss: 0.11,  accuracy: 0.98\n",
      "Epoch 35.00,  loss: 0.08,  accuracy: 0.98\n",
      "Epoch 40.00,  loss: 0.06,  accuracy: 0.98\n",
      "Epoch 45.00,  loss: 0.04,  accuracy: 0.99\n",
      "Epoch 50.00,  loss: 1.00,  accuracy: 0.72\n",
      "Epoch 55.00,  loss: 0.42,  accuracy: 0.81\n",
      "Epoch 60.00,  loss: 0.36,  accuracy: 0.85\n",
      "Epoch 65.00,  loss: 0.32,  accuracy: 0.85\n",
      "Epoch 70.00,  loss: 0.30,  accuracy: 0.86\n",
      "Epoch 75.00,  loss: 0.30,  accuracy: 0.86\n",
      "Epoch 80.00,  loss: 0.28,  accuracy: 0.86\n",
      "Epoch 85.00,  loss: 0.27,  accuracy: 0.86\n",
      "Epoch 90.00,  loss: 0.28,  accuracy: 0.86\n",
      "Epoch 95.00,  loss: 0.27,  accuracy: 0.86\n",
      "Took: 914.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# Q3.2 Normal with lr high \n",
    "train(batch_size= 256, epochs=100, lr=0.1, act=nn.ReLU(), pool=nn.MaxPool2d(2), optim=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comment\n",
    " With high learning rate, accuracy was improved but loss was decreased.  45th epoch was the most optimal. And oscillated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.00,  loss: 0.82,  accuracy: 0.71\n",
      "Epoch 5.00,  loss: 0.36,  accuracy: 0.88\n",
      "Epoch 10.00,  loss: 0.37,  accuracy: 0.89\n",
      "Epoch 15.00,  loss: 0.34,  accuracy: 0.89\n",
      "Epoch 20.00,  loss: 0.30,  accuracy: 0.89\n",
      "Epoch 25.00,  loss: 0.27,  accuracy: 0.89\n",
      "Epoch 30.00,  loss: 0.27,  accuracy: 0.89\n",
      "Epoch 35.00,  loss: 0.28,  accuracy: 0.89\n",
      "Epoch 40.00,  loss: 0.27,  accuracy: 0.89\n",
      "Epoch 45.00,  loss: 0.28,  accuracy: 0.89\n",
      "Epoch 50.00,  loss: 0.27,  accuracy: 0.89\n",
      "Epoch 55.00,  loss: 0.27,  accuracy: 0.89\n",
      "Epoch 60.00,  loss: 0.26,  accuracy: 0.89\n",
      "Epoch 65.00,  loss: 0.26,  accuracy: 0.89\n",
      "Epoch 70.00,  loss: 0.26,  accuracy: 0.89\n",
      "Epoch 75.00,  loss: 0.26,  accuracy: 0.89\n",
      "Epoch 80.00,  loss: 0.26,  accuracy: 0.89\n",
      "Epoch 85.00,  loss: 0.26,  accuracy: 0.89\n",
      "Epoch 90.00,  loss: 0.26,  accuracy: 0.89\n",
      "Epoch 95.00,  loss: 0.26,  accuracy: 0.89\n",
      "Took: 934.11 seconds\n"
     ]
    }
   ],
   "source": [
    "# Q4 sgdWithMomentum\n",
    "train(batch_size= 256, epochs=100, lr=0.01, act=nn.ReLU(), pool=nn.MaxPool2d(2), optim=\"sgdWithMomentum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comment\n",
    " Reached optimal state faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.00,  loss: 0.50,  accuracy: 0.85\n",
      "Epoch 5.00,  loss: 0.44,  accuracy: 0.89\n",
      "Epoch 10.00,  loss: 0.43,  accuracy: 0.89\n",
      "Epoch 15.00,  loss: 0.43,  accuracy: 0.89\n",
      "Epoch 20.00,  loss: 0.43,  accuracy: 0.89\n",
      "Epoch 25.00,  loss: 0.42,  accuracy: 0.89\n",
      "Epoch 30.00,  loss: 0.42,  accuracy: 0.89\n",
      "Epoch 35.00,  loss: 0.42,  accuracy: 0.89\n",
      "Epoch 40.00,  loss: 0.42,  accuracy: 0.89\n",
      "Epoch 45.00,  loss: 0.41,  accuracy: 0.89\n",
      "Epoch 50.00,  loss: 0.41,  accuracy: 0.89\n",
      "Epoch 55.00,  loss: 0.41,  accuracy: 0.89\n",
      "Epoch 60.00,  loss: 0.40,  accuracy: 0.89\n",
      "Epoch 65.00,  loss: 0.40,  accuracy: 0.89\n",
      "Epoch 70.00,  loss: 0.39,  accuracy: 0.89\n",
      "Epoch 75.00,  loss: 0.39,  accuracy: 0.89\n",
      "Epoch 80.00,  loss: 0.39,  accuracy: 0.89\n",
      "Epoch 85.00,  loss: 0.38,  accuracy: 0.89\n",
      "Epoch 90.00,  loss: 0.38,  accuracy: 0.89\n",
      "Epoch 95.00,  loss: 0.37,  accuracy: 0.89\n",
      "Took: 920.87 seconds\n"
     ]
    }
   ],
   "source": [
    "# Q4 adagrad\n",
    "train(batch_size= 256, epochs=100, lr=0.01, act=nn.ReLU(), pool=nn.MaxPool2d(2), optim=\"adagrad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_predict_y = model(test_x.float()).detach()\n",
    "_predict_ys = np.argmax(predict_y, axis=-1)\n",
    "_label_np = test_label.numpy()\n",
    "_ = predict_ys == test_label\n",
    "_correct += np.sum(_.numpy(), axis=-1)\n",
    "_sum += _.shape[0]\n",
    "correct/_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comment \n",
    " slow improvement on loss\n",
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "723af08ac1a383e201c46d44f5d93e4810900547575f554f7cd507ba66e971d0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
